# Amazon EKS API サーバーのモニタリング

このオブザーバビリティのベストプラクティスガイドのセクションでは、API サーバーモニタリングに関連する次のトピックを深掘りします。

* Amazon EKS API サーバーモニタリングの概要
* API サーバートラブルシューティングダッシュボードの設定
* API トラブルシューティングダッシュボードを使用した API サーバーの問題の理解
* API サーバーへの無制限なリストコールの理解  
* API サーバーへの悪影響を及ぼす動作の停止
* API の優先順位と公平性
* 最も遅い API 呼び出しと API サーバーレイテンシの問題の特定

### はじめに

Amazon EKS で管理されるコントロールプレーンのモニタリングは、EKS クラスターの正常性に関する問題を事前に特定するための非常に重要な Day 2 運用アクティビティです。Amazon EKS コントロールプレーンモニタリングにより、収集されたメトリクスに基づいて予防措置を講じることができます。これらのメトリクスは、API サーバーのトラブルシューティングと、内部的な問題の特定に役立ちます。

このセクションでは、Amazon EKS API サーバーモニタリングのデモンストレーションに Amazon Managed Service for Prometheus(AMP)を使用し、メトリクスの可視化には Amazon Managed Grafana(AMG)を使用します。Prometheus は、強力なクエリ機能を備え、さまざまなワークロードで広くサポートされている一般的なオープンソースのモニタリングツールです。Amazon Managed Service for Prometheus は、Amazon EKS、[Amazon Elastic Container Service(Amazon ECS)](http://aws.amazon.com/ecs)、[Amazon Elastic Compute Cloud(Amazon EC2)](http://aws.amazon.com/ec2)などの環境を安全かつ信頼性高くモニタリングするのに役立つ、完全マネージドの Prometheus 互換サービスです。[Amazon Managed Grafana](https://aws.amazon.com/grafana/) は、複数のデータソースからアプリケーションの運用メトリクス、ログ、トレースを即座にクエリ、相関分析、可視化できるようにする、オープンソースの Grafana の完全マネージドかつセキュアなデータ可視化サービスです。

はじめに、Amazon Managed Service for Prometheus と Amazon Managed Grafana を使用して、Prometheus で [Amazon Elastic Kubernetes Service(Amazon EKS)](https://aws.amazon.com/eks) API サーバーのトラブルシューティングを支援するスターターダッシュボードを設定します。次のセクションでは、EKS API サーバーのトラブルシューティング時に発生する問題の理解、API の優先順位と公平性、悪い動作の停止などについて詳しく説明します。最後に、アクションを実行して Amazon EKS クラスターの状態を正常に保つのに役立つ、最も遅い API 呼び出しと API サーバーレイテンシの問題を特定することについて詳しく説明します。

### API サーバー障害対応ダッシュボードの設定

[Amazon Elastic Kubernetes Service(Amazon EKS)](https://aws.amazon.com/eks) API サーバーの障害対応を支援するためのスターターダッシュボードを設定します。 これを使用して、実稼働 EKS クラスターの障害対応中にメトリクスを理解するのに役立ちます。 収集されたメトリクスに焦点を当て、Amazon EKS クラスターの障害対応中にその重要性を理解します。

まず、[Amazon EKS クラスターからメトリクスを収集し、Amazon Managed Service for Prometheus に送信するための ADOT コレクターを設定します](https://aws.amazon.com/blogs/containers/metrics-and-traces-collection-using-amazon-eks-add-ons-for-aws-distro-for-opentelemetry/)。 この設定では、EKS ADOT アドオンを使用します。これにより、EKS クラスターがアップおよび実行された後いつでも ADOT をアドオンとして有効にできます。 ADOT アドオンには、最新のセキュリティパッチとバグ修正が含まれており、Amazon EKS で機能することが AWS によって検証されています。 この設定では、EKS クラスターに ADOT アドオンをインストールする方法と、クラスターからメトリクスを収集するためにそれを使用する方法を示します。

次に、最初のステップで設定した AMP をデータソースとして使用して、[Amazon Managed Grafana ワークスペースを設定し、メトリクスを視覚化します](https://aws.amazon.com/blogs/mt/amazon-managed-grafana-getting-started/)。 最後に、[API 障害対応ダッシュボードをダウンロードし](https://github.com/RiskyAdventure/Troubleshooting-Dashboards/blob/main/api-troubleshooter.json)、Amazon Managed Grafana に移動して、さらなる障害対応のためにメトリクスを視覚化する API 障害対応ダッシュボード json をアップロードします。

### API トラブルシューティングダッシュボードを使用して問題を理解する

クラスタにインストールしたい興味深いオープンソースプロジェクトが見つかったとします。そのオペレータは、不正なリクエストを使用したり、必要以上に高頻度の LIST 呼び出しを行ったり、場合によっては 1,000 ノードのすべてにわたってデーモンセットをデプロイし、クラスタの 50,000 ポッドのステータスを毎分確認しているかもしれません。

こうしたことが本当に頻繁に起こるのでしょうか。はい、そうなのです! なぜそうなるのか、ちょっとしたヒントを紹介します。

#### LIST と WATCH の違いを理解する

クラスタ内のオブジェクトの状態を理解する必要があるアプリケーションがあります。 たとえば、マシンラーニング(ML)アプリケーションは、*Completed* ステータスでない Pod の数を理解することによってジョブのステータスを知りたいとします。 Kubernetes では、WATCH と呼ばれるものでこれを上手く行う方法があります。また、クラスタ上のすべてのオブジェクトをリストアップして、それらの Pod の最新のステータスを見つけるというあまり望ましくない方法もあります。

#### 適切に動作するWATCH

Kubernetesでプッシュモデルを使って更新を受信するためにWATCHや長期間生存する単一の接続を使うことが、最もスケーラブルな更新の方法です。
少し単純化して説明すると、システムの完全な状態を要求し、そのオブジェクトの変更が受信されたときにのみキャッシュ内のオブジェクトを更新し、更新を見逃していないことを確認するために定期的に再同期を実行します。

下の画像では、`apiserver_longrunning_gauge`を使用して、両方のAPIサーバー全体でこれらの長期間生存する接続の数を取得しています。

![API-MON-1](../../../../../images/Containers/aws-native/eks/api-mon-1.jpg)

*図: `apiserver_longrunning_gauge` メトリック*

この効率的なシステムであっても、良いことが過ぎることがあります。 
たとえば、多くの非常に小さなノードを使用し、APIサーバーと通信する必要がある2つ以上のデーモンセットを使用している場合、システムのWATCHコールの数を不必要に劇的に増加させることが非常に簡単です。
たとえば、8つのxlargeノードと1つの8xlargeノードの違いを見てみましょう。
ここでは、システムのWATCHコールが8倍に増加しているのがわかります。

![API-MON-2](../../../../../images/Containers/aws-native/eks/api-mon-2.jpg)  

*図: 8つのxlargeノードのWATCHコール*

これらは効率的な呼び出しですが、前述の不適切な呼び出しであった場合はどうでしょうか?
上記の1,000ノードのそれぞれにあるデーモンセットの1つが、クラスター内の合計50,000のPodのそれぞれについて更新を要求していることを想像してみてください。
次のセクションでは、この無制限のリストコールのアイデアを探求します。  

続ける前に、上記の例のような統合は細心の注意を払って行わなければならず、考慮しなければならない他の多くの要因があることを注意深く警告しておきます。
システムのCPUの限られた数で競合するスレッドの遅延の問題から、Podのチャーンレート、ノードが安全に処理できる最大ボリュームアタッチメント数まで、考慮しなければならないことはたくさんあります。
しかし、私たちの焦点は、問題が発生する前に対処できる実行可能なステップにつながるメトリックにあるでしょう。そして、設計についての新しい洞察を得ることができるかもしれません。  

WATCHメトリックはシンプルなものですが、WATCHの数を追跡および削減するために使用できます。 
この数を減らすために考えられるいくつかのオプションは以下のとおりです。

* 履歴を追跡するためにHelmが作成するConfigMapの数を制限する  
* 不変のConfigMapとSecretを使用する(WATCHを使用しない)
* 賢明なノードサイジングと統合

### API サーバーへの無制限なリストコールの理解

話題にしていたリストコールについてです。リストコールは、オブジェクトの状態を理解するたびに、Kubernetes オブジェクトの全履歴をプルすることです。このとき、キャッシュには何も保存されません。

これがどの程度の影響を与えるかは、エージェントのリクエスト数、リクエストの頻度、リクエストされるデータ量によって異なります。クラスター全体のすべてを要求しているのか、単一の名前空間のみを要求しているのか。それが毎分、すべてのノードで発生しているのか。例として、ノードから送信されるすべてのログに Kubernetes のメタデータを追加しているロギングエージェントを使用しましょう。これは、大規模なクラスターでは膨大なデータ量になる可能性があります。エージェントがリストコールを介してそのデータを取得する方法は多数ありますので、いくつかを見ていきましょう。

以下のリクエストは、特定の名前空間から Pod を要求しています。

`/api/v1/namespaces/my-namespace/pods`

次に、クラスター上のすべての 50,000 個の Pod を要求しますが、500 個の Pod ずつのチャンクで取得します。 

`/api/v1/pods?limit=500`

次のコールが最も破壊的なものです。クラスター全体のすべての 50,000 個の Pod を一度に取得することです。

`/api/v1/pods`

これは現場でかなり一般的に発生しており、ログで確認できます。

### API サーバーへの悪い動作の停止

このような悪い動作からクラスターをどのように保護できるでしょうか。Kubernetes 1.20 より前は、API サーバーが 1 秒間に処理される *inflight* リクエストの数を制限することによって自身を保護していました。etcd は一度に特定のパフォーマンスでリクエストを処理できる数に限界があるため、etcd の読み取りと書き込みのレイテンシを許容範囲に保つ 1 秒間当たりのリクエスト数に制限する必要があります。残念ながら、この記事を書いている時点では、これを動的に行う方法はありません。

下のチャートでは、デフォルトの最大 400 の inflight リクエスト/ API サーバー、デフォルトの最大 200 の同時書き込みリクエストの内訳を読み取るリクエストを確認できます。デフォルトの EKS クラスターでは、合計 800 の読み取りと 400 の書き込みの 2 つの API サーバーがあります。ただし、アップグレード後など、サーバーに非対称な負荷がかかる場合があるため、注意が必要です。

![API-MON-3](../../../../../images/Containers/aws-native/eks/api-mon-3.jpg)

*図: 読み取りリクエストの内訳を示す Grafana チャート。*

上記のスキームは完璧なものではなかったことが判明しました。たとえば、API サーバーのすべての inflight 書き込みリクエストを使い切って、ノードのキープアライブメッセージなどの重要なリクエストを遅延させる可能性のある、今インストールしたこのひどい動作の新しいオペレーターをどのようにして阻止できるでしょうか。

### API の優先順位と公平性

1 秒間に読み取り/書き込みリクエストがいくつ開いているかを心配する代わりに、容量を 1 つの総数として扱い、クラスター上の各アプリケーションがその最大数の公平な割合またはシェアを得ることができたらどうでしょうか。

それを効果的に行うには、API サーバーにリクエストを送信したものを特定し、そのリクエストにある種の名前タグを付ける必要があります。この新しい名前タグを使用することで、これらのリクエストはすべて、「おしゃべり」と呼ぶ新しいエージェントからのものであることがわかります。これで、同じ DaemonSet からのリクエストであることを識別する *フロー* と呼ばれるものに、おしゃべりのすべてのリクエストをグループ化できるようになります。この概念により、この悪いエージェントを制限し、クラスター全体を消費しないようにすることができます。

ただし、すべてのリクエストが同じではありません。クラスターを操作可能な状態に保つために必要なコントロールプレーントラフィックは、新しいオペレーターよりも優先度が高くする必要があります。ここで優先レベルの概念が登場します。重要度の高いトラフィック、高優先度トラフィック、低優先度トラフィックのための「バケット」またはキューをデフォルトでいくつか用意しておき、チャティエージェントのフローが重要なトラフィックキューで公平なシェアを得ることができないようにすることはできないでしょうか。ただし、そのトラフィックを低優先度キューに入れることができます。こうすることでそのフローは、おそらく他のおしゃべりエージェントと競合することになります。次に、各優先レベルが API サーバーが処理できる最大数の適切なシェアまたは割合を持つことを確認し、リクエストの遅延が大きくなり過ぎないようにする必要があります。

#### 優先順位と公平性の実践

これは比較的新しい機能なので、多くの既存のダッシュボードは、最大インフライト読み取りと最大インフライト書き込みの古いモデルを使用しています。なぜこれが問題になるのでしょうか。

kube-system 名前空間のすべてに高い優先順位のタグを付けていたとします。しかし、その重要な名前空間に不適切なエージェントをインストールしたり、単純にその名前空間に過剰にアプリケーションをデプロイした場合はどうでしょう。回避しようとしたのと同じ問題が発生する可能性があります。したがって、このような状況を注意深く監視する必要があります。

この種の問題を追跡するのに最も興味深いメトリクスをいくつか抽出してみました。


* 優先度グループのシェアのうち、何パーセントが使用されているか?
* リクエストがキューで待機した最長時間はどれくらいか?  
* どのフローが最も多くのシェアを使用しているか?
* システムに予期しない遅延があるか?

#### 使用率のパーセント

ここでは、クラスター上のさまざまなデフォルトの優先度グループと、最大値の何パーセントが使用されているかを示しています。

![API-MON-4](../../../../../images/Containers/aws-native/eks/api-mon-4.jpg)

*図: クラスター上の優先度グループ。*

#### キュー内のリクエスト時間

優先キュー内で処理されるまでリクエストが待機した秒数です。

![API-MON-5](../../../../../images/Containers/aws-native/eks/api-mon-5.jpg)

*図: 優先キュー内のリクエスト時間*

#### フロー別の実行回数上位

どのフローが最も大きなシェアを占めているでしょうか。

![API-MON-6](../../../../../images/Containers/aws-native/eks/api-mon-6.jpg)

*図: フロー別の実行回数上位*

#### リクエスト実行時間

処理に意外な遅延はありませんか?

![API-MON-7](../../../../../images/Containers/aws-native/eks/api-mon-7.jpg)

*図: フロー制御リクエスト実行時間。*

### 最も遅い API 呼び出しと API サーバーのレイテンシ問題の特定

API のレイテンシを引き起こす要因の性質を理解したので、一歩下がって全体像を見渡すことができます。ダッシュボードのデザインは単に、調査すべき問題があるかどうかのスナップショットを取得しようとしていることを忘れてはいけません。詳細な分析には、PromQL を使用したアドホッククエリー、あるいはさらに良い方法としてログクエリを使用します。

高レベルのメトリクスとして確認したいアイデアは何でしょうか?

* 完了まで最も時間のかかる API 呼び出しは何ですか?
    * その呼び出しは何をしているのですか? (オブジェクトの一覧表示、削除など)
    * その操作の対象となっているオブジェクトは何ですか? (Pod、Secret、ConfigMap など)
* API サーバー自体にレイテンシの問題がありますか?
    * 優先度の高いキューの 1 つでリクエストのバックアップを引き起こす遅延がありますか?
* etcd サーバーがレイテンシを経験しているために、API サーバーが遅いように見えるだけですか?

#### 最も遅い API 呼び出し

以下のチャートでは、その期間で最も時間がかかった API 呼び出しを探しています。この場合、05:40 の時間帯で最も待ち時間の長い呼び出しである LIST 関数を呼び出しているカスタムリソース定義(CRD)が見られます。このデータを使って、その時間帯の監査ログから LIST リクエストを CloudWatch Insights でプルすることができ、これがどのアプリケーションかを確認できます。

![API-MON-8](../../../../../images/Containers/aws-native/eks/api-mon-8.jpg)

*図: 上位5つの最も遅い API 呼び出し。*

#### API リクエスト期間

この API レイテンシーチャートは、1 分のタイムアウト値に近づいているリクエストがあるかどうかを理解するのに役立ちます。以下のように時間経過とともにヒストグラムが表示される形式が好きです。なぜなら、線グラフでは隠れてしまうデータの外れ値が確認できるからです。

![API-MON-9](../../../../../images/Containers/aws-native/eks/api-mon-9.jpg)

*図: API リクエスト期間のヒートマップ。*

バケットの上にカーソルを置くだけで、約 25 ミリ秒かかった呼び出しの正確な数がわかります。  
[Image: Image.jpg]*図: 25 ミリ秒以上かかった呼び出し。*

この概念は、リクエストをキャッシュする他のシステムで動作しているときに重要です。キャッシュリクエストは高速です。これらのリクエストレイテンシを、より遅いリクエストとマージしたくありません。ここでは、キャッシュされたリクエストとキャッシュされていないリクエストの2つの明確なレイテンシバンドが確認できます。

![API-MON-10](../../../../../images/Containers/aws-native/eks/api-mon-10.jpg)  

*図: レイテンシ、キャッシュされたリクエスト。*

#### ETCD リクエスト期間

ETCD のレイテンシは、Kubernetes のパフォーマンスにおいて最も重要な要因の 1 つです。Amazon EKS では、`request_duration_seconds_bucket` メトリクスを見ることで、API サーバーの視点からこのパフォーマンスを確認できます。

![API-MON-11](../../../../../images/Containers/aws-native/eks/api-mon-11.jpg)

*図 : `request_duration_seconds_bucket` メトリクス。*

ここで学んだことを、特定のイベントが相関しているかどうかを確認することで組み合わせ始めることができます。下のチャートでは、API サーバーのレイテンシを確認できますが、このレイテンシの多くが etcd サーバーから発生していることもわかります。ひと目で正しい問題領域にすばやく移動できることが、ダッシュボードを強力にすることです。

![API-MON-12](../../../../../images/Containers/aws-native/eks/api-mon-12.jpg)

*図: Etcd リクエスト*

## まとめ

オブザーバビリティのベストプラクティスガイドのこのセクションでは、Amazon Managed Service for Prometheus と Amazon Managed Grafana を使用した[スターターダッシュボード](https://github.com/RiskyAdventure/Troubleshooting-Dashboards/blob/main/api-troubleshooter.json)を利用して、[Amazon Elastic Kubernetes Service(Amazon EKS)](https://aws.amazon.com/eks) API サーバのトラブルシューティングを支援しました。さらに、EKS API サーバのトラブルシューティング中に発生する問題の理解を深め、API の優先順位と公平性、悪い動作の停止について検討しました。最後に、最も遅い API 呼び出しと API サーバのレイテンシの問題を特定することで、Amazon EKS クラスタの状態を健全に保つためのアクションを取るのに役立ちました。さらなる深堀りについては、AWS の [One Observability Workshop](https://catalog.workshops.aws/observability/en-US) の AWS ネイティブのオブザーバビリティカテゴリのアプリケーションモニタリングモジュールを実践することを強くおすすめします。
